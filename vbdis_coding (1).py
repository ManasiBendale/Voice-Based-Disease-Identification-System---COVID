# -*- coding: utf-8 -*-
"""VBDIS_CODING

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mzsB8Kk7ADyq26p8FHg_pbHQ-rzDUujp

Importing the Scipy Library
"""

import os
import numpy as np 
import scipy.io.wavfile

"""Reading the Audio File"""

sample_rate, signal = scipy.io.wavfile.read('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav')

"""Data Type and Shape"""

print(type(signal), type(sample_rate))

"""The audio signal with normal sample rate

# **The sample rate is the number of samples of audio carried per second, measured in Hz or kHz.**
"""

print(signal.shape, sample_rate)

"""# **Librosa Library**

Importing the Librosa Library
"""

import librosa

"""Reading the Audio File"""

signal_lbr , signal_rate_lbr = librosa.load('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav')

"""Data Type and Shape"""

print(type(signal_lbr), type(signal_rate_lbr))

"""The audio signal rate is sampled at of Nyquist Rate

# **The sample rate is the number of samples of audio carried per second, measured in Hz or kHz.**
"""

print(signal_lbr.shape, signal_rate_lbr)

## Some Parameter Changes

signal_lbr , signal_rate_lbr = librosa.load('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav', sr=44100)

print(type(signal_lbr), type(signal_rate_lbr))

print(signal_lbr.shape, signal_rate_lbr)

## Some Parameter Changes

signal_lbr , signal_rate_lbr = librosa.load('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav', sr=None)

print(type(signal_lbr), type(signal_rate_lbr))

print(signal_lbr.shape, signal_rate_lbr)

"""# **IPython Library**

Playing Audio File using IPython Widget
"""

from IPython import display

display.Audio('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav')

"""# **Audio Data Visualization**"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

plt.figure(figsize=(18, 5))

plt.plot(signal)
plt.show()

"""**Zooming into the Specific Zone**"""

plt.figure(figsize=(18, 5))

plt.title("COVID'19 Cough")
plt.ylabel("Amplitude")
plt.xlabel("Time")

Sample = signal[5500:6000]

plt.plot(Sample)
plt.show()

"""# **Time Series Plot**"""

Time = np.linspace(0, len(signal) / sample_rate, num=len(signal))

plt.figure(figsize=(18, 5))

plt.title("COVID'19 Cough")
plt.ylabel("Amplitude")
plt.xlabel("Time")

plt.plot(Time, signal)
plt.show()

plt.figure(figsize=(18, 10))

plt.subplot(211)
plt.title('Spectrogram of a wav file with COVID\'19 Cough')
plt.plot(signal)
plt.xlabel('Sample')
plt.ylabel('Amplitude')

plt.subplot(212)
plt.specgram(signal[:,0],Fs=sample_rate)
plt.xlabel('Time')
plt.ylabel('Frequency') 

plt.show()

# Plot the signal read from wav file
plt.figure(figsize=(15, 15))

plt.subplot(311)
plt.title('Audio Plot of a wav file with COVID\'19 Cough')
plt.plot(signal[5500:6500])
plt.xlabel('Samples')
plt.ylabel('Amplitude')

plt.subplot(312)
plt.title('Spectrogram of a wav file with COVID\'19 Cough')
plt.specgram(signal[5500:6500,0],Fs=sample_rate)
plt.xlabel('Time')
plt.ylabel('Frequency')

plt.subplot(313)
plt.title("Time Series Plot of a wav file with COVID'19 Cough")
plt.ylabel("Amplitude")
plt.xlabel("Time")

Time = np.linspace(0, len(signal[5500:6500,0]) / sample_rate, num=len(signal[5500:6500,0]))
plt.plot(Time, signal[5500:6500])


plt.show()

"""# **Deep Learning in Audio Classification**"""

import librosa.display

signal , sample_rate = librosa.load('/content/drive/MyDrive/content_Dust_Bin_COVID19_Cough.wav')

plt.figure(figsize=(15, 5))

librosa.display.waveplot(signal, sr=sample_rate)

"""# **Spectrogram**"""

X = librosa.stft(signal)

Xdb = librosa.amplitude_to_db(abs(X))

plt.figure(figsize=(14, 10))

plt.subplot(211)
librosa.display.waveplot(signal, sr=sample_rate)

plt.subplot(212)
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')


plt.colorbar(orientation="horizontal")

"""A spectrogram is a visual way of representing the signal strength, or “loudness”, 
        of a signal over time at various frequencies present in a particular waveform. 

Not only can one see whether there is more or less energy at, 
        for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.

A spectrogram is usually depicted as a heat map, i.e., 
        as an image with the intensity shown by varying the color or brightness.
"""

## Some Testing

X = librosa.stft(signal[1:2])

Xdb = librosa.amplitude_to_db(abs(X))

plt.figure(figsize=(14, 10))

plt.subplot(211)
librosa.display.waveplot(signal, sr=sample_rate)

plt.subplot(212)
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')


plt.colorbar(orientation="horizontal")

signal.shape

## Testing

Zoom_Area_Start = 22000
Zoom_Area_End = 26000

X = librosa.stft(signal[Zoom_Area_Start : Zoom_Area_End])

Xdb = librosa.amplitude_to_db(abs(X))



plt.figure(figsize=(15, 15))

plt.subplot(211)
librosa.display.waveplot(signal[Zoom_Area_Start : Zoom_Area_End], sr=sample_rate)

plt.subplot(212)
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')


plt.colorbar(orientation="horizontal")

plt.figure(figsize=(15, 25))

librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')

"""COVID'19 Cough Audio Recording [Source](https://www.youtube.com/watch?v=8VA73zW2DXY).

Patient Details:
Age: 49
Sex: Male
Country: UK
Day: 5
Resource Date: Mar 23, 2020
Infection Symptoms: cannot Breathe, Heavy Coughs.
Health Status before effected by COVID'19: Fit, Regular Swimmer
"""

from IPython import display

display.Audio('/content/drive/MyDrive/content_COVID19_Cough_UK_49M_D5.wav')

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from scipy.io import wavfile
import librosa ## For Audio in Python
import librosa.display

pip install python_speech_features

from python_speech_features import mfcc, logfbank  ## To digital Signal Processing

def calc_fft(y, rate):
    n = len(y)
    freq = np.fft.rfftfreq(n, d = 1/rate)
    Y = abs(np.fft.rfft(y)/n)
    return (Y, freq)

def envelope(y, rate, threshold):
    mask = []
    y = pd.Series(y).apply(np.abs)
    y_mean = y.rolling(window = int(rate/10), min_periods = 1, center = True).mean()
    for mean in y_mean:
        if mean > threshold:
            mask.append(True)
        else:
            mask.append(False)
    return mask

from tqdm import tqdm

"""# **User Defined**"""

def plot_signals(signals):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Time Series', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(signals.keys())[i])
            axes[y].plot(list(signals.values())[i])
            i += 1

def plot_fft(fft):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Fourier Transforms', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            data = list(fft.values())[i]
            Y, freq = data[0], data[1]
            axes[y].set_title(list(fft.keys())[i])
            axes[y].plot(freq, Y)
            i += 1

def plot_fbank(fbank):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Filter Bank Coefficients', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(fbank.keys())[i])
            axes[y].imshow(list(fbank.values())[i], cmap='hot', interpolation='nearest')
            i += 1

def plot_mfccs(mfccs):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Mel Frequency Cepstrum Coefficients', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(mfccs.keys())[i])
            axes[y].imshow(list(mfccs.values())[i], cmap='hot', interpolation='nearest')
            i += 1

def calc_fft(y, rate):
    n = len(y)
    freq = np.fft.rfftfreq(n, d = 1/rate)
    Y = abs(np.fft.rfft(y)/n)
    return (Y, freq)

def envelope(y, rate, threshold):
    mask = []
    y = pd.Series(y).apply(np.abs)
    y_mean = y.rolling(window = int(rate/10), min_periods = 1, center = True).mean()
    for mean in y_mean:
        if mean > threshold:
            mask.append(True)
        else:
            mask.append(False)
    return mask

"""
## **Data Extraction and Visualization** - Manasi"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from IPython import display
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

pip install python_speech_features

from scipy.io import wavfile
import librosa ## For Audio in Python

from python_speech_features import mfcc, logfbank  ## To digital Signal Processing

"""# **User Defined**

"""

def plot_signals(signals):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Time Series', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(signals.keys())[i])
            axes[y].plot(list(signals.values())[i])
            i += 1

def plot_fft(fft):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Fourier Transforms', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            data = list(fft.values())[i]
            Y, freq = data[0], data[1]
            axes[y].set_title(list(fft.keys())[i])
            axes[y].plot(freq, Y)
            i += 1

def plot_fbank(fbank):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Filter Bank Coefficients', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(fbank.keys())[i])
            axes[y].imshow(list(fbank.values())[i], cmap='hot', interpolation='nearest')
            i += 1

def plot_mfccs(mfccs):
    fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(20,5))
    fig.suptitle('Mel Frequency Cepstrum Coefficients', size=16)
    i = 0
    for x in range(1):
        for y in range(2):
            axes[y].set_title(list(mfccs.keys())[i])
            axes[y].imshow(list(mfccs.values())[i], cmap='hot', interpolation='nearest')
            i += 1

def calc_fft(y, rate):
    n = len(y)
    freq = np.fft.rfftfreq(n, d = 1/rate)
    Y = abs(np.fft.rfft(y)/n)
    return (Y, freq)

def envelope(y, rate, threshold):
    mask = []
    y = pd.Series(y).apply(np.abs)
    y_mean = y.rolling(window = int(rate/10), min_periods = 1, center = True).mean()
    for mean in y_mean:
        if mean > threshold:
            mask.append(True)
        else:
            mask.append(False)
    return mask

os.listdir('/content/drive/MyDrive/Temp_Dataset')

os.listdir('/content/drive/MyDrive/Temp_Dataset/train')

classes = list(os.listdir('/content/drive/MyDrive/Temp_Dataset/train'))

print("Number of Classes in the Data Set:", len(classes), "Classes")
print("The classes of the dataset are   :", classes[0], ",", classes[1])

"""Next? Create a dataframe.

What should the dataframe contain?
1. Fname
2. Class
3. Length
of the Audio Files in each directory
"""

column_names = ['Fname','Class', 'Length']
df = pd.DataFrame(columns = column_names)
df.info()

df.head() ## The dataframe is empty as of now

#dataset_directory = 'Dataset/Train/'
dataset_directory = '/content/drive/MyDrive/Temp_Dataset/train/'

for c in list(classes):
  print('Number of files in the directory \'{}\' are {}'.format(c,len(os.listdir(dataset_directory+c))))

import signal
import sys
import time
import threading
from os.path import dirname 
from scipy.io import wavfile
import scipy.io

for c in list(classes):
    for n,f in enumerate(os.listdir(dataset_directory+c)):
        rate, signal = wavfile.read(dataset_directory+str(c)+'/'+str(f))
        length = signal.shape[0]/rate
        f_df = pd.DataFrame({
            "Fname": str(f),
            "Class": str(c),
            "Length": length}, index = [n])
        df = df.append(f_df)

df.info()

df.set_index('Fname', inplace=True)
df.info()

df.head()

class_dist = df.groupby(['Class'])['Length'].mean()

class_dist

fig, ax = plt.subplots()
ax.set_title("Class Distribution", y=1.08)
ax.pie(class_dist, labels = class_dist.index, autopct = '%1.1f%%',
      shadow = False, startangle=90)
ax.axis('equal')
plt.show()

"""# **Visualization of Audio Data in Both Classes and Feature Extraction**"""

df.reset_index(inplace=True)

signals = {}
fft     = {}
fbank   = {}
mfccs   = {}

for c in classes:
    
    wav_file = df[df.Class == c].iloc[int(np.random.choice(df[df.Class == c].shape[0])),0]
    print("The audio File is {}".format(wav_file))    
    display.display(display.Audio(dataset_directory+c+"/"+wav_file))
    
    signal, rate = librosa.load(dataset_directory+c+"/"+wav_file, sr=44100)
    
    signals[c] = signal
    fft[c] = calc_fft(signal, rate)
    
    bank = logfbank(signal[:rate], rate, nfilt=26, nfft=1103).T
    fbank[c] = bank
    
    mel = mfcc(signal[:rate], rate, numcep= 13, nfilt=26, nfft= 1103).T
    mfccs[c] = mel

plot_signals(signals)

plot_fft(fft)

plot_fbank(fbank)

plot_mfccs(mfccs)
plt.show()

for c in classes:
    
    wav_file = df[df.Class == c].iloc[int(np.random.choice(df[df.Class == c].shape[0])),0]
    print("The audio File is {}".format(wav_file))    
    display.display(display.Audio(dataset_directory+c+"/"+wav_file))
    
    signal, rate = librosa.load(dataset_directory+c+"/"+wav_file, sr=44100)
    
    signals[c] = signal
    fft[c] = calc_fft(signal, rate)
    
    bank = logfbank(signal[:rate], rate, nfilt=26, nfft=1103).T
    fbank[c] = bank
    
    mel = mfcc(signal[:rate], rate, numcep= 13, nfilt=26, nfft= 1103).T
    mfccs[c] = mel

plot_signals(signals)

plot_fft(fft)

plot_fbank(fbank)

plot_mfccs(mfccs)
plt.show()

"""# **RNN Model Building and Saving Model** - Garvit"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile

pip install python_speech_features

from python_speech_features import mfcc

from tqdm import tqdm

from keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense
from keras.layers import LSTM, TimeDistributed

from keras.models import Sequential

from keras.utils import to_categorical

from sklearn.utils.class_weight import compute_class_weight

import pickle

from keras.callbacks import ModelCheckpoint

"""# **User Defined**"""

class Config:
    def __init__(self, mode= 'conv', nfilt=26, nfeat=13, nfft = 2048, rate = 16000):
        self.mode = mode
        self.nfilt = nfilt
        self.nfeat = nfeat
        self.nfft = nfft
        self.rate = rate
        self.step = int(rate/10)
        self.model_path = os.path.join('/content/drive/MyDrive/models', mode + '.model')
        self.p_path = os.path.join('/content/drive/MyDrive/pickles', mode + '.p')

def check_data():
    if os.path.isfile(config.p_path):
        print('Loading existing data for {} model'.format(config.mode))
        with open(config.p_path, 'rb') as handle:
            tmp = pickle.load(handle)
            return tmp
    else:
        return None

def build_rand_feat():
    tmp = check_data()
    if tmp:
        return tmp.data[0], tmp.data[1]
        
    X = []
    y = []
    
    _min, _max = float('inf'), -float('inf')
    
    for _ in tqdm(range(n_samples)):
        
        rand_class = np.random.choice(class_dist.index, p = prob_dist)
        
        file = np.random.choice(df[df.Class==rand_class].index)
        
        rate, wav = wavfile.read(dataset_directory+str(rand_class)+"/"+str(file))
        Class = df.at[file, 'Class']
        
        rand_index = np.random.randint(0, wav.shape[0]-config.step)
        
        sample = wav[rand_index : rand_index + config.step]
        X_sample = mfcc(sample, rate, numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)
        
        _min = min(np.amin(X_sample), _min)
        _max = max(np.amax(X_sample), _max)
        
        X.append(X_sample)
        y.append(classes.index(Class))
        
    
    config.min = _min
    config.max = _max
    
    X, y = np.array(X), np.array(y)
    X = (X- _min) / (_max - _min)
    
    if config.mode == 'conv':
        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)
    elif config.mode =='time':
        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])
    
    y = to_categorical(y, num_classes=2)
    
    config.data = (X, y)
    
    with open(config.p_path, 'wb') as handle:
        pickle.dump(config, handle, protocol=2)
    
    return X,y

def get_reccurent_model():
    ### Shape of data for RNN is (n, time, freq)
    model = Sequential()
    
    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(128, return_sequences=True))
    
    model.add(TimeDistributed(Dense(64, activation='relu')))
    model.add(TimeDistributed(Dense(32, activation='relu')))
    model.add(TimeDistributed(Dense(16, activation='relu')))
    
    model.add(Flatten())
    model.add(Dropout(0.5))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(2, activation='sigmoid'))
    model.summary()
    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['acc'])
    
    return model

"""# **Data Extraction**"""

os.listdir('/content/drive/MyDrive/Temp_Dataset')

from google.colab import drive
drive.mount('/content/drive')

classes = list(os.listdir('/content/drive/MyDrive/Temp_Dataset/train'))

print("Number of Classes in the Data Set:", len(classes), "Classes")
print("The classes of the dataset are   :", classes[0], ",", classes[1])

"""Creating the dataframe with basic column names

"""

column_names = ['Fname','Class', 'Length']
df = pd.DataFrame(columns = column_names)
df.info()

# dataset_directory = 'Dataset/Train/'
dataset_directory = '/content/drive/MyDrive/Temp_Dataset/train/'

for c in list(classes):
    print('Number of files in the directory \'{}\' are {}'.format(c,len(os.listdir(dataset_directory+c))))

for c in list(classes):
    for n,f in tqdm(enumerate(os.listdir(dataset_directory+c))):
        rate, signal = wavfile.read(dataset_directory+str(c)+"/"+str(f))
        length = signal.shape[0]/rate
        f_df = pd.DataFrame({
            "Fname": str(f),
            "Class": str(c),
            "Length": length}, index = [n])
        df = df.append(f_df)

df.info()

class_dist = df.groupby(['Class'])['Length'].mean()
class_dist

df.set_index('Fname', inplace=True)
df.info()

"""# **RNN Model using LSTM**"""

n_samples = 2 * int(df['Length'].sum()/0.1)
prob_dist = class_dist / class_dist.sum()
choices = np.random.choice(class_dist.index, p= prob_dist)

config = Config(mode = 'time')
config

import os
import sys
import pickle

X,y = build_rand_feat()

y_flat = np.argmax(y, axis =1)

input_shape = (X.shape[1], X.shape[2])

model = get_reccurent_model()

"""# **Adding Checkpoints**"""

checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc', verbose=1, mode='max',
                            save_best_only=True, save_weights_only=False, period=1)

model.fit(X, y, epochs=1, batch_size=32, shuffle = True, validation_split=0.1, callbacks=[checkpoint])

fig, axes = plt.subplots(nrows=1, ncols=1, sharex=False, sharey=True, figsize=(20,8))

# Plot accuracy per iteration
plt.plot(model.history.history['acc'][:50], label='acc')
plt.plot(model.history.history['val_acc'][:50], label='val_acc')
plt.legend()

plt.title('Custom Built LSTM RNN Model\'s Training Analysis on the sickness and non-sickness Audio Data', size=16)
plt.xlabel("Epochs")
plt.ylabel("accuracy reached")

plt.show()

"""# **Predicting Sick and Non-Sick Audio** - Jaya 

"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile

from python_speech_features import mfcc

from tqdm import tqdm

from keras.models import load_model

import pickle

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix

"""# **User Defined**

"""

def build_predictions(audio_dir):
    y_true = []
    y_pred = []
    
    fn_prob = {}
    
    print('Extracting features from audio')
    
    for fn in tqdm(os.listdir(audio_dir)):
        rate, wav = wavfile.read(os.path.join(audio_dir, fn))
        Class = fn2class[fn]
        c = classes.index(Class)
        y_prob = []
        
        for i in range(0,wav.shape[0] - config.step, config.step):
            sample = wav[i : i+config.step]
            x = mfcc(sample, rate, numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)
            
            x = (x - config.min) / (config.max - config.min)
            
            if config.mode == 'conv':
                x = x.reshape(1, x.shape[0], x.shape[1], 1)
            elif config.mode == 'time':
                x = np.expand_dims(x, axis = 0)
            
            y_hat = model.predict(x)
            y_prob.append(y_hat)
            y_pred.append(np.argmax(y_hat))
            y_true.append(c)
            
        fn_prob[fn] = np.mean(y_prob, axis = 0).flatten()
    return y_true, y_pred, fn_prob

"""# **Creating the dataframe with basic column names**"""

column_names = ['Fname','Class', 'Length']
df = pd.DataFrame(columns = column_names)
df.info()

# dataset_directory = 'Dataset/validation/'
dataset_directory = '/content/drive/MyDrive/Temp_Dataset/train/'

for c in list(classes):
    print('Number of files in the directory \'{}\' are {}'.format(c,len(os.listdir(dataset_directory+c))))

for c in list(classes):
    for n,f in tqdm(enumerate(os.listdir(dataset_directory+c))):
        rate, signal = wavfile.read(dataset_directory+str(c)+"/"+str(f))
        length = signal.shape[0]/rate
        f_df = pd.DataFrame({
            "Fname": str(f),
            "Class": str(c),
            "Length": length}, index = [n])
        df = df.append(f_df)

df.info()

fn2class = dict(zip(df.Fname, df.Class))

len(fn2class)

"""# **Loading Models**"""

p_path = os.path.join('pickles', '/content/drive/MyDrive/pickles/time.p')

with open(p_path, 'rb') as handle:
    config = pickle.load(handle)

from tensorflow import keras
model = keras.models.load_model('/content/drive/MyDrive/models/time.model')

y_true, y_pred, fn_prob = build_predictions('/content/drive/MyDrive/Temp_train/')

acc_score = accuracy_score(y_true=y_true, y_pred=y_pred)
acc_score

df.to_csv('predictions.csv', index = False)

print(y_pred)

model.save=('model.h5')

model.save=('time.model')

import weakref

pickle.dump(model,open('model.pkl','wb'))
model=pickle.load(open('model.pkl','rb'))

!pip install pyyaml h5py

